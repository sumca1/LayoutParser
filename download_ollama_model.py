#!/usr/bin/env python3
"""
ğŸ¤– Ollama Model Downloader via GitHub Actions + git
××¢×¨×›×ª ×œ×”×•×¨×“×ª ××•×“×œ×™ Ollama ×“×¨×š GitHub Actions ×¢× git sparse-checkout
"""

import os
import sys
import subprocess
import time
from pathlib import Path
from typing import Optional
import requests
import json
from datetime import datetime

class OllamaModelDownloader:
    """××•×¨×™×“ ××•×“×œ×™ Ollama ×“×¨×š GitHub Actions + git"""
    
    def __init__(self, github_token: str, repo: str = "sumca1/ollama-models"):
        self.token = github_token
        self.repo = repo
        self.headers = {
            'Authorization': f'token {github_token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.base_url = f"https://api.github.com/repos/{repo}"
        
    def trigger_download(self, model_name: str, chunk_size_mb: int = 1900) -> Optional[int]:
        """
        ××¤×¢×™×œ GitHub Actions workflow ×œ×”×•×¨×“×ª ××•×“×œ
        
        Args:
            model_name: ×©× ×”××•×“×œ (×œ××©×œ: llama3.1:8b)
            chunk_size_mb: ×’×•×“×œ chunk ×‘××’×”-×‘×ª×™× (×‘×¨×™×¨×ª ××—×“×œ: 1900)
            
        Returns:
            run_id ×©×œ ×”workflow ××• None ×× × ×›×©×œ
        """
        workflow_url = f"{self.base_url}/actions/workflows/download-ollama-model.yml/dispatches"
        
        payload = {
            'ref': 'main',
            'inputs': {
                'model_name': model_name,
                'chunk_size_mb': str(chunk_size_mb)
            }
        }
        
        print(f"ğŸš€ ××¤×¢×™×œ ×”×•×¨×“×ª {model_name} ×‘-GitHub Actions...")
        response = requests.post(workflow_url, headers=self.headers, json=payload)
        
        if response.status_code == 204:
            print(f"âœ… Workflow ×”×•×¤×¢×œ ×‘×”×¦×œ×—×”!")
            # × ×¡×” ×œ××¦×•× ××ª ×”-run_id
            time.sleep(5)  # ×”××ª×Ÿ ×©×”workflow ×™×ª×—×™×œ
            return self._find_latest_run()
        else:
            print(f"âŒ ×©×’×™××” ×‘×”×¤×¢×œ×ª workflow: {response.status_code}")
            print(response.text)
            return None
            
    def _find_latest_run(self) -> Optional[int]:
        """××•×¦× ××ª ×”-run ×”××—×¨×•×Ÿ"""
        runs_url = f"{self.base_url}/actions/runs"
        response = requests.get(runs_url, headers=self.headers)
        
        if response.status_code == 200:
            runs = response.json().get('workflow_runs', [])
            if runs:
                return runs[0]['id']
        return None
        
    def wait_for_completion(self, run_id: int, timeout: int = 3600) -> bool:
        """
        ×××ª×™×Ÿ ×œ×¡×™×•× ×”workflow
        
        Args:
            run_id: ××–×”×” ×”×¨×™×¦×”
            timeout: ×–××Ÿ ×”××ª× ×” ××§×¡×™××œ×™ ×‘×©× ×™×•×ª
            
        Returns:
            True ×× ×”×¦×œ×™×—, False ×× × ×›×©×œ ××• timeout
        """
        run_url = f"{self.base_url}/actions/runs/{run_id}"
        start_time = time.time()
        
        print(f"â³ ×××ª×™×Ÿ ×œ×¡×™×•× ×”×•×¨×“×” (timeout: {timeout//60} ×“×§×•×ª)...")
        
        while time.time() - start_time < timeout:
            response = requests.get(run_url, headers=self.headers)
            
            if response.status_code != 200:
                print(f"âŒ ×©×’×™××” ×‘×‘×“×™×§×ª ×¡×˜×˜×•×¡: {response.status_code}")
                return False
                
            run = response.json()
            status = run['status']
            conclusion = run.get('conclusion')
            
            elapsed = int(time.time() - start_time)
            print(f"ğŸ“Š ×¡×˜×˜×•×¡: {status} | ×–××Ÿ: {elapsed//60}:{elapsed%60:02d}", end='\r')
            
            if status == 'completed':
                print(f"\n{'âœ…' if conclusion == 'success' else 'âŒ'} Workflow ×”×¡×ª×™×™×: {conclusion}")
                return conclusion == 'success'
                
            time.sleep(30)  # ×‘×“×™×§×” ×›×œ 30 ×©× ×™×•×ª
            
        print(f"\nâ° Timeout - ×”workflow ×œ× ×”×¡×ª×™×™× ×ª×•×š {timeout//60} ×“×§×•×ª")
        return False
        
    def download_via_git(self, model_name: str, output_dir: str = ".") -> bool:
        """
        ××•×¨×™×“ ××ª ×”××•×“×œ ×-GitHub ×“×¨×š git sparse-checkout
        
        Args:
            model_name: ×©× ×”××•×“×œ (×‘×“×™×•×§ ×›××• ×©×”×•×¢×œ×”)
            output_dir: ×ª×™×§×™×™×ª ×™×¢×“
            
        Returns:
            True ×× ×”×¦×œ×™×—
        """
        model_folder = model_name.replace(':', '_')  # llama3.1:8b -> llama3.1_8b
        output_path = Path(output_dir) / model_folder
        
        print(f"\nğŸ“¥ ××•×¨×™×“ {model_name} ×“×¨×š git sparse-checkout...")
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×–×× ×™×ª
            temp_repo = Path(output_dir) / f"temp_ollama_repo_{int(time.time())}"
            temp_repo.mkdir(exist_ok=True, parents=True)
            
            # Clone ×¢× sparse-checkout
            print(f"ğŸ”§ ××ª×—×™×œ git clone...")
            subprocess.run([
                'git', 'clone',
                '--depth', '1',
                '--filter=blob:none',
                '--sparse',
                f'https://{self.token}@github.com/{self.repo}.git',
                str(temp_repo)
            ], check=True, capture_output=True)
            
            # ×”×’×“×¨×ª sparse-checkout
            print(f"ğŸ¯ ××’×“×™×¨ sparse-checkout ×œ-{model_folder}...")
            subprocess.run([
                'git', '-C', str(temp_repo),
                'sparse-checkout', 'set', model_folder
            ], check=True, capture_output=True)
            
            # ×”×¢×‘×¨×ª ×”×§×‘×¦×™×
            model_source = temp_repo / model_folder
            if model_source.exists():
                print(f"ğŸ“¦ ××¢×ª×™×§ ×§×‘×¦×™×...")
                import shutil
                if output_path.exists():
                    shutil.rmtree(output_path)
                shutil.copytree(model_source, output_path)
                print(f"âœ… ×”×§×‘×¦×™× ×”×•×¢×ª×§×• ×œ-{output_path}")
                
                # × ×™×§×•×™
                print(f"ğŸ§¹ ×× ×§×” ×§×‘×¦×™× ×–×× ×™×™×...")
                try:
                    shutil.rmtree(temp_repo)
                except:
                    print(f"âš ï¸  ×œ× ×”×¦×œ×™×— ×œ××—×•×§ {temp_repo} - ×ª×•×›×œ ×œ××—×•×§ ×™×“× ×™×ª")
                
                return True
            else:
                print(f"âŒ ×œ× × ××¦××” ×ª×™×§×™×™×”: {model_source}")
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ ×©×’×™××ª git: {e}")
            if e.stderr:
                print(f"stderr: {e.stderr.decode()}")
            return False
        except Exception as e:
            print(f"âŒ ×©×’×™××”: {e}")
            return False
            
    def install_to_ollama(self, model_dir: str, model_name: str) -> bool:
        """
        ××ª×§×™×Ÿ ××ª ×”××•×“×œ ×‘-Ollama
        
        Args:
            model_dir: ×ª×™×§×™×™×ª ×”××•×“×œ ×©×”×•×¨×“
            model_name: ×©× ×”××•×“×œ (llama3.1:8b)
            
        Returns:
            True ×× ×”×¦×œ×™×—
        """
        model_path = Path(model_dir)
        
        # ×‘×“×™×§×” ×× ×¦×¨×™×š reassemble
        parts = list(model_path.glob("part_*"))
        if parts:
            print(f"ğŸ”§ ××–×”×” {len(parts)} ××§×˜×¢×™× - ×××—×“...")
            output_file = model_path / "models.tar.gz"
            
            # ××™×—×•×“
            with open(output_file, 'wb') as outfile:
                for part in sorted(parts):
                    print(f"  ğŸ“ {part.name}")
                    with open(part, 'rb') as infile:
                        outfile.write(infile.read())
            
            print(f"âœ… ××•×—×“ ×œ-{output_file}")
        else:
            output_file = model_path / "models.tar.gz"
            if not output_file.exists():
                print(f"âŒ ×œ× × ××¦× ×§×•×‘×¥ models.tar.gz")
                return False
        
        # ×—×™×œ×•×¥ ×œ-Ollama
        ollama_dir = Path.home() / ".ollama"
        print(f"ğŸ“¦ ××—×œ×¥ ×œ-{ollama_dir}...")
        
        try:
            import tarfile
            with tarfile.open(output_file, 'r:gz') as tar:
                tar.extractall(ollama_dir)
            
            print(f"âœ… ×”××•×“×œ ×”×•×ª×§×Ÿ!")
            
            # ×‘×“×™×§×”
            print(f"\nğŸ§ª ×‘×•×“×§ ××ª ×”××•×“×œ...")
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            if model_name in result.stdout:
                print(f"âœ… {model_name} ××•×ª×§×Ÿ ×•××•×›×Ÿ ×œ×©×™××•×©!")
                return True
            else:
                print(f"âš ï¸  ×”××•×“×œ ×”×•×ª×§×Ÿ ××‘×œ ×œ× ××•×¤×™×¢ ×‘×¨×©×™××”")
                print(f"× ×¡×”: ollama run {model_name}")
                return False
                
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×”×ª×§× ×”: {e}")
            return False
            
    def download_and_install(self, model_name: str, wait: bool = True) -> bool:
        """
        ×ª×”×œ×™×š ××œ×: ×”×¤×¢×œ×ª ×”×•×¨×“×” + ×”××ª× ×” + ×”×•×¨×“×” + ×”×ª×§× ×”
        
        Args:
            model_name: ×©× ×”××•×“×œ (llama3.1:8b)
            wait: ×”×× ×œ×—×›×•×ª ×œ×¡×™×•× ××• ×œ×—×–×•×¨ ××™×“
            
        Returns:
            True ×× ×”×›×œ ×”×¦×œ×™×—
        """
        print(f"\n{'='*70}")
        print(f"ğŸ¤– ××ª×—×™×œ ×”×•×¨×“×ª {model_name}")
        print(f"{'='*70}\n")
        
        # ×©×œ×‘ 1: ×”×¤×¢×œ×ª workflow
        run_id = self.trigger_download(model_name)
        if not run_id:
            print("âŒ × ×›×©×œ ×‘×”×¤×¢×œ×ª workflow")
            return False
            
        if not wait:
            print(f"âœ… Workflow ×”×•×¤×¢×œ (run_id: {run_id})")
            print(f"×”×¨×¥ ×©×•×‘ ×¢× wait=True ×›×©×”workflow ×™×¡×ª×™×™×")
            return True
            
        # ×©×œ×‘ 2: ×”××ª× ×” ×œ×¡×™×•×
        if not self.wait_for_completion(run_id):
            print("âŒ Workflow × ×›×©×œ ××• timeout")
            return False
            
        # ×©×œ×‘ 3: ×”×•×¨×“×” ×“×¨×š git
        if not self.download_via_git(model_name):
            print("âŒ × ×›×©×œ ×‘×”×•×¨×“×” ×GitHub")
            return False
            
        # ×©×œ×‘ 4: ×”×ª×§× ×”
        model_folder = model_name.replace(':', '_')
        if not self.install_to_ollama(model_folder, model_name):
            print("âŒ × ×›×©×œ ×‘×”×ª×§× ×”")
            return False
            
        print(f"\n{'='*70}")
        print(f"ğŸ‰ {model_name} ×”×•×ª×§×Ÿ ×‘×”×¦×œ×—×”!")
        print(f"{'='*70}\n")
        print(f"× ×¡×”: ollama run {model_name}")
        
        return True


def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ğŸ¤– ×”×•×¨×“×ª ××•×“×œ×™ Ollama ×“×¨×š GitHub Actions + git'
    )
    parser.add_argument('model', help='×©× ×”××•×“×œ (×œ××©×œ: llama3.1:8b)')
    parser.add_argument('--token', default=os.getenv('GITHUB_TOKEN'),
                       help='GitHub token (××• ××©×ª× ×” GITHUB_TOKEN)')
    parser.add_argument('--repo', default='sumca1/ollama-models',
                       help='×©× ×”repository')
    parser.add_argument('--no-wait', action='store_true',
                       help='××œ ×ª×—×›×” ×œ×¡×™×•× ×”workflow')
    parser.add_argument('--chunk-size', type=int, default=1900,
                       help='×’×•×“×œ chunk ×‘××’×”-×‘×ª×™×')
    
    args = parser.parse_args()
    
    if not args.token:
        print("âŒ ×—×¡×¨ GitHub token!")
        print("×”×’×“×¨: $env:GITHUB_TOKEN='your_token'")
        print("××• ×”×¢×‘×¨: --token your_token")
        sys.exit(1)
        
    downloader = OllamaModelDownloader(args.token, args.repo)
    success = downloader.download_and_install(args.model, wait=not args.no_wait)
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
