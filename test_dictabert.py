"""
DictaBERT - ××•×“×œ × ×™×§×•×“ ×¢×‘×¨×™×ª ××ª×§×“×
××•×“×œ: dicta-il/dictabert-large-char-menaked
"""

from transformers import AutoTokenizer, AutoModel
import torch

# ×˜×¢×Ÿ ××ª ×”××•×“×œ
print("ğŸ“¥ ×˜×•×¢×Ÿ DictaBERT...")
model_name = "dicta-il/dictabert-large-char-menaked"

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name, trust_remote_code=True)

print("âœ… ×”××•×“×œ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”!")
print(f"ğŸ“Š ×’×•×“×œ ××•×“×œ: {model_name}")

# ×“×•×’××” ×œ×©×™××•×©
def add_nikud(text):
    """××•×¡×™×£ × ×™×§×•×“ ×œ×˜×§×¡×˜ ×¢×‘×¨×™×ª"""
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    # ×›××Ÿ ×¦×¨×™×š ×œ×¢×‘×“ ××ª ×”×¤×œ×˜ ×‘×”×ª×× ×œ-API ×©×œ ×”××•×“×œ
    return outputs

# ×“×•×’××”
if __name__ == "__main__":
    text = "×©×œ×•× ×¢×•×œ×"
    print(f"\nğŸ§ª ×‘×•×“×§ ×¢×: '{text}'")
    
    result = add_nikud(text)
    print(f"âœ… ×”××•×“×œ ×¢×‘×“!")
    print(f"ğŸ“Š ×¦×•×¨×ª ×¤×œ×˜: {result.last_hidden_state.shape}")
    
    print("\nğŸ’¡ ×œ×©×™××•×© ××ª×§×“×, ×¨××”: https://huggingface.co/dicta-il/dictabert-large-char-menaked")
